{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"autoencoder .ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"oOXDpGQde7RD","colab_type":"code","colab":{}},"source":["# Code to read file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticating email\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","import logging\n","logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)\n","#2.1 Get the file\n","downloaded = drive.CreateFile({'id':'1NmX5DgGI3BhHtstc3m-BTdWRnmXou6jB'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('ml-1m.zip')\n","downloaded = drive.CreateFile({'id':'1yDNaNh_WHdkKfLgE2ayOrXlIxneTGp2g'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('ml-100k.zip')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kerawKDfSYk","colab_type":"code","colab":{}},"source":["!unzip ml-1m.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zcx_BjT6fSfQ","colab_type":"code","colab":{}},"source":["!unzip ml-100k.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgOy4U8bhUae","colab_type":"code","colab":{}},"source":["# Importing the libraries\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z84C2OEOfOjG","colab_type":"code","colab":{}},"source":["# Importing the dataset\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2v8TQReDhjrt","colab_type":"code","colab":{}},"source":["# Preparing the training set and the test set\n","training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztpzdoXIhqvO","colab_type":"code","colab":{}},"source":["# Getting the number of users and movies\n","nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n","nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mi-amLCqhuy3","colab_type":"code","colab":{}},"source":["# Converting the data into an array with users in lines and movies in columns\n","def convert(data):\n","    new_data = []\n","    for id_users in range(1, nb_users + 1):\n","        id_movies = data[:,1][data[:,0] == id_users]\n","        id_ratings = data[:,2][data[:,0] == id_users]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies - 1] = id_ratings\n","        new_data.append(list(ratings))\n","    return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl2Q98GWh0iD","colab_type":"code","colab":{}},"source":["# Converting the data into Torch tensors\n","training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKF0NPW5h7Ss","colab_type":"code","colab":{}},"source":["# Creating the architecture of the Neural Network\n","class SAE(nn.Module):\n","    def __init__(self, ):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0m7XpuIiD94","colab_type":"code","colab":{}},"source":["sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I3_aaTakQY1","colab_type":"code","colab":{}},"source":["# Training the SAE\n","nb_epoch = 200\n","for epoch in range(1, nb_epoch + 1):\n","    train_loss = 0\n","    s = 0.\n","    for id_user in range(nb_users):\n","        input = Variable(training_set[id_user]).unsqueeze(0)\n","        target = input.clone()\n","        if torch.sum(target.data > 0) > 0:\n","            output = sae(input)\n","            target.require_grad = False\n","            output[target == 0] = 0\n","            loss = criterion(output, target)\n","            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","            loss.backward()\n","            train_loss += np.sqrt(loss.data.item()*mean_corrector)\n","            s += 1.\n","            optimizer.step()\n","    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vasZV7SriHYT","colab_type":"code","colab":{}},"source":["# Testing the SAE\n","test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = Variable(test_set[id_user])\n","    if torch.sum(target.data > 0) > 0:\n","        output = sae(input)\n","        target.require_grad = False\n","        output[(target == 0).unsqueeze(0)] = 0\n","        loss = criterion(output, target)\n","        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","        test_loss += np.sqrt(loss.data.item()*mean_corrector)\n","        s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":0,"outputs":[]}]}