{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Boltzmann Machines .ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"oOXDpGQde7RD","colab_type":"code","colab":{}},"source":["# Code to read file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticating email\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","import logging\n","logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)\n","#2.1 Get the file\n","downloaded = drive.CreateFile({'id':'1NmX5DgGI3BhHtstc3m-BTdWRnmXou6jB'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('ml-1m.zip')\n","downloaded = drive.CreateFile({'id':'1yDNaNh_WHdkKfLgE2ayOrXlIxneTGp2g'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('ml-100k.zip')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kerawKDfSYk","colab_type":"code","colab":{}},"source":["!unzip ml-1m.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zcx_BjT6fSfQ","colab_type":"code","colab":{}},"source":["!unzip ml-100k.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgOy4U8bhUae","colab_type":"code","colab":{}},"source":["# Importing the libraries\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z84C2OEOfOjG","colab_type":"code","colab":{}},"source":["# Importing the dataset\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2v8TQReDhjrt","colab_type":"code","colab":{}},"source":["# Preparing the training set and the test set\n","training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztpzdoXIhqvO","colab_type":"code","colab":{}},"source":["# Getting the number of users and movies\n","nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n","nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mi-amLCqhuy3","colab_type":"code","colab":{}},"source":["# Converting the data into an array with users in lines and movies in columns\n","def convert(data):\n","    new_data = []\n","    for id_users in range(1, nb_users + 1):\n","        id_movies = data[:,1][data[:,0] == id_users]\n","        id_ratings = data[:,2][data[:,0] == id_users]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies - 1] = id_ratings\n","        new_data.append(list(ratings))\n","    return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl2Q98GWh0iD","colab_type":"code","colab":{}},"source":["# Converting the data into Torch tensors\n","training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIHZsCfMh4KF","colab_type":"code","colab":{}},"source":["# Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n","training_set[training_set == 0] = -1\n","training_set[training_set == 1] = 0\n","training_set[training_set == 2] = 0\n","training_set[training_set >= 3] = 1\n","test_set[test_set == 0] = -1\n","test_set[test_set == 1] = 0\n","test_set[test_set == 2] = 0\n","test_set[test_set >= 3] = 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKF0NPW5h7Ss","colab_type":"code","colab":{}},"source":["# Creating the architecture of the Neural Network\n","class RBM():\n","    def __init__(self, nv, nh):\n","        self.W = torch.randn(nh, nv)\n","        self.a = torch.randn(1, nh)\n","        self.b = torch.randn(1, nv)\n","    def sample_h(self, x):\n","        wx = torch.mm(x, self.W.t())\n","        activation = wx + self.a.expand_as(wx)\n","        p_h_given_v = torch.sigmoid(activation)\n","        return p_h_given_v, torch.bernoulli(p_h_given_v)\n","    def sample_v(self, y):\n","        wy = torch.mm(y, self.W)\n","        activation = wy + self.b.expand_as(wy)\n","        p_v_given_h = torch.sigmoid(activation)\n","        return p_v_given_h, torch.bernoulli(p_v_given_h)\n","    def train(self, v0, vk, ph0, phk):\n","        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n","        self.b += torch.sum((v0 - vk), 0)\n","        self.a += torch.sum((ph0 - phk), 0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0m7XpuIiD94","colab_type":"code","colab":{}},"source":["nv = len(training_set[0])\n","nh = 100\n","batch_size = 100\n","rbm = RBM(nv, nh)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I3_aaTakQY1","colab_type":"code","colab":{}},"source":["# Training the RBM\n","nb_epoch = 10\n","for epoch in range(1, nb_epoch + 1):\n","    train_loss = 0\n","    s = 0.\n","    for id_user in range(0, nb_users - batch_size, batch_size):\n","        vk = training_set[id_user:id_user+batch_size]\n","        v0 = training_set[id_user:id_user+batch_size]\n","        ph0,_ = rbm.sample_h(v0)\n","        for k in range(10):\n","            _,hk = rbm.sample_h(vk)\n","            _,vk = rbm.sample_v(hk)\n","            vk[v0<0] = v0[v0<0]\n","        phk,_ = rbm.sample_h(vk)\n","        rbm.train(v0, vk, ph0, phk)\n","        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n","        s += 1.\n","    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vasZV7SriHYT","colab_type":"code","colab":{}},"source":["# Testing the RBM\n","test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","    v = training_set[id_user:id_user+1]\n","    vt = test_set[id_user:id_user+1]\n","    if len(vt[vt>=0]) > 0:\n","        _,h = rbm.sample_h(v)\n","        _,v = rbm.sample_v(h)\n","        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n","        s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhSKo2BxBtCD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}